{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "QZkvfk1yrFtZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=in_channels,\n",
        "                           out_channels=out_channels,\n",
        "                           kernel_size=3,\n",
        "                           padding=1,\n",
        "                           bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.conv2 = nn.Conv2d(in_channels=out_channels,\n",
        "                           out_channels=out_channels,\n",
        "                           kernel_size=3,\n",
        "                           padding=1,\n",
        "                           bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(num_features=out_channels)\n",
        "    self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bn1(self.conv1(x))\n",
        "    x = self.relu(x)\n",
        "    x = self.bn2(self.conv2(x))\n",
        "    return self.relu(x)"
      ],
      "metadata": {
        "id": "MA1Q907frNkH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "conv = ConvBlock(in_channels=1, out_channels=64).to(device)"
      ],
      "metadata": {
        "id": "NuRUqvJfrNmL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randint(low=0, high=255, size=(1, 1, 256, 256), dtype=torch.float32).to(device)\n",
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9nSrqhcsu6Y",
        "outputId": "45719883-c965-4630-c643-5602c5d496fd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conv(input).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Zv_Gk8OrNoc",
        "outputId": "6aac697a-8ea1-433c-d1e8-8cc860564bef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.conv_block = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=in_channels,\n",
        "                           out_channels=out_channels,\n",
        "                           kernel_size=3,\n",
        "                           padding=1,\n",
        "                           bias=False),\n",
        "        nn.BatchNorm2d(num_features=out_channels),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Conv2d(in_channels=out_channels,\n",
        "                           out_channels=out_channels,\n",
        "                           kernel_size=3,\n",
        "                           padding=1,\n",
        "                           bias=False),\n",
        "        nn.BatchNorm2d(num_features=out_channels),\n",
        "        nn.ReLU(inplace=True)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.conv_block(x)"
      ],
      "metadata": {
        "id": "ldL3cpnFrNqt"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.encoder = nn.Sequential(\n",
        "        nn.MaxPool2d(kernel_size=2),\n",
        "        ConvBlock(in_channels=in_channels, out_channels=out_channels),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.encoder(x)"
      ],
      "metadata": {
        "id": "qjNQ_BE9rNsi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = Encoder(in_channels=64, out_channels=128).to(device)"
      ],
      "metadata": {
        "id": "_xKE4-K9rN14"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randint(low=0, high=255, size=(1, 64, 128, 128), dtype=torch.float32).to(device)\n",
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yJSIHonIwIJ3",
        "outputId": "08856b43-29c9-443f-d23e-192e4b5acb50"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 128, 128])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enc(input).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0k68SuSwP81",
        "outputId": "c0735eac-413c-48e6-94d1-0578807ef20f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 128, 64, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.trans_conv = nn.ConvTranspose2d(in_channels=in_channels, out_channels=out_channels,\n",
        "                                         kernel_size=4, stride=2, padding=1)\n",
        "    self.conv_block = ConvBlock(in_channels=in_channels, out_channels=out_channels)\n",
        "\n",
        "  def forward(self, x1, x2):\n",
        "    # print(x1.shape, x2.shape)\n",
        "    x = self.trans_conv(x1)\n",
        "    # print(\"After transpose: \", x.shape)\n",
        "    x = torch.cat([x2, x], dim=1)\n",
        "    # print(\"after concat: \", x.shape)\n",
        "    return self.conv_block(x)"
      ],
      "metadata": {
        "id": "ohhop9lvrN2-"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec = Decoder(in_channels=128, out_channels=64).to(device)"
      ],
      "metadata": {
        "id": "DpMlGxKMrN4C"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1 = torch.randint(high=8, size=(1, 128, 128, 128), dtype=torch.float32, device=device)\n",
        "x2 = torch.randint(high=8, size=(1, 64, 256, 256), dtype=torch.float32, device=device)"
      ],
      "metadata": {
        "id": "X8HXCTLVi1V6"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dec(x1, x2).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6reP-GQrN5A",
        "outputId": "bdde8a90-96ab-4098-cc01-9969f4e403af"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128, 128, 128]) torch.Size([1, 64, 256, 256])\n",
            "After transpose:  torch.Size([1, 64, 256, 256])\n",
            "after concat:  torch.Size([1, 128, 256, 256])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNET(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels):\n",
        "    super().__init__()\n",
        "    self.in_conv = ConvBlock(in_channels=in_channels, out_channels=64)\n",
        "    self.enc_1 = Encoder(in_channels=64, out_channels=128)\n",
        "    self.enc_2 = Encoder(in_channels=128, out_channels=256)\n",
        "    self.enc_3 = Encoder(in_channels=256, out_channels=512)\n",
        "    self.enc_4 = Encoder(in_channels=512, out_channels=1024)\n",
        "\n",
        "    self.dec_1 = Decoder(in_channels=1024, out_channels=512)\n",
        "    self.dec_2 = Decoder(in_channels=512, out_channels=256)\n",
        "    self.dec_3 = Decoder(in_channels=256, out_channels=128)\n",
        "    self.dec_4 = Decoder(in_channels=128, out_channels=64)\n",
        "\n",
        "    self.out_conv = nn.Conv2d(in_channels=64, out_channels=out_channels,\n",
        "                              kernel_size=1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x1 = self.in_conv(x)\n",
        "    x2 = self.enc_1(x1)\n",
        "    x3 = self.enc_2(x2)\n",
        "    x4 = self.enc_3(x3)\n",
        "    x5 = self.enc_4(x4)\n",
        "\n",
        "    x = self.dec_1(x5, x4)\n",
        "    x = self.dec_2(x, x3)\n",
        "    x = self.dec_3(x, x2)\n",
        "    x = self.dec_4(x, x1)\n",
        "    return self.out_conv(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "x8htkWborN6I"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNET(in_channels=1, out_channels=2).to(device)"
      ],
      "metadata": {
        "id": "3BRFx_lClW0r"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randint(low=0, high=255, size=(1, 1, 256, 256), dtype=torch.float32).to(device)\n",
        "input.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8EgH14wjmOO",
        "outputId": "c98c81ef-a0e2-40b3-a188-6e4a2077672d"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(input).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0WcKE3kjmQv",
        "outputId": "55c418b0-0ad5-43ed-b5e9-005522fb964e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1024, 16, 16]) torch.Size([1, 512, 32, 32])\n",
            "After transpose:  torch.Size([1, 512, 32, 32])\n",
            "after concat:  torch.Size([1, 1024, 32, 32])\n",
            "torch.Size([1, 512, 32, 32]) torch.Size([1, 256, 64, 64])\n",
            "After transpose:  torch.Size([1, 256, 64, 64])\n",
            "after concat:  torch.Size([1, 512, 64, 64])\n",
            "torch.Size([1, 256, 64, 64]) torch.Size([1, 128, 128, 128])\n",
            "After transpose:  torch.Size([1, 128, 128, 128])\n",
            "after concat:  torch.Size([1, 256, 128, 128])\n",
            "torch.Size([1, 128, 128, 128]) torch.Size([1, 64, 256, 256])\n",
            "After transpose:  torch.Size([1, 64, 256, 256])\n",
            "after concat:  torch.Size([1, 128, 256, 256])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 256, 256])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (1, 256, 256))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhvPTnpvrN7m",
        "outputId": "7d0f4501-0def-473c-a57d-00ff64af0e76"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 256, 256]             576\n",
            "       BatchNorm2d-2         [-1, 64, 256, 256]             128\n",
            "              ReLU-3         [-1, 64, 256, 256]               0\n",
            "            Conv2d-4         [-1, 64, 256, 256]          36,864\n",
            "       BatchNorm2d-5         [-1, 64, 256, 256]             128\n",
            "              ReLU-6         [-1, 64, 256, 256]               0\n",
            "         ConvBlock-7         [-1, 64, 256, 256]               0\n",
            "         MaxPool2d-8         [-1, 64, 128, 128]               0\n",
            "            Conv2d-9        [-1, 128, 128, 128]          73,728\n",
            "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
            "             ReLU-11        [-1, 128, 128, 128]               0\n",
            "           Conv2d-12        [-1, 128, 128, 128]         147,456\n",
            "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
            "             ReLU-14        [-1, 128, 128, 128]               0\n",
            "        ConvBlock-15        [-1, 128, 128, 128]               0\n",
            "          Encoder-16        [-1, 128, 128, 128]               0\n",
            "        MaxPool2d-17          [-1, 128, 64, 64]               0\n",
            "           Conv2d-18          [-1, 256, 64, 64]         294,912\n",
            "      BatchNorm2d-19          [-1, 256, 64, 64]             512\n",
            "             ReLU-20          [-1, 256, 64, 64]               0\n",
            "           Conv2d-21          [-1, 256, 64, 64]         589,824\n",
            "      BatchNorm2d-22          [-1, 256, 64, 64]             512\n",
            "             ReLU-23          [-1, 256, 64, 64]               0\n",
            "        ConvBlock-24          [-1, 256, 64, 64]               0\n",
            "          Encoder-25          [-1, 256, 64, 64]               0\n",
            "        MaxPool2d-26          [-1, 256, 32, 32]               0\n",
            "           Conv2d-27          [-1, 512, 32, 32]       1,179,648\n",
            "      BatchNorm2d-28          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-29          [-1, 512, 32, 32]               0\n",
            "           Conv2d-30          [-1, 512, 32, 32]       2,359,296\n",
            "      BatchNorm2d-31          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-32          [-1, 512, 32, 32]               0\n",
            "        ConvBlock-33          [-1, 512, 32, 32]               0\n",
            "          Encoder-34          [-1, 512, 32, 32]               0\n",
            "        MaxPool2d-35          [-1, 512, 16, 16]               0\n",
            "           Conv2d-36         [-1, 1024, 16, 16]       4,718,592\n",
            "      BatchNorm2d-37         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-38         [-1, 1024, 16, 16]               0\n",
            "           Conv2d-39         [-1, 1024, 16, 16]       9,437,184\n",
            "      BatchNorm2d-40         [-1, 1024, 16, 16]           2,048\n",
            "             ReLU-41         [-1, 1024, 16, 16]               0\n",
            "        ConvBlock-42         [-1, 1024, 16, 16]               0\n",
            "          Encoder-43         [-1, 1024, 16, 16]               0\n",
            "  ConvTranspose2d-44          [-1, 512, 32, 32]       8,389,120\n",
            "           Conv2d-45          [-1, 512, 32, 32]       4,718,592\n",
            "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-47          [-1, 512, 32, 32]               0\n",
            "           Conv2d-48          [-1, 512, 32, 32]       2,359,296\n",
            "      BatchNorm2d-49          [-1, 512, 32, 32]           1,024\n",
            "             ReLU-50          [-1, 512, 32, 32]               0\n",
            "        ConvBlock-51          [-1, 512, 32, 32]               0\n",
            "          Decoder-52          [-1, 512, 32, 32]               0\n",
            "  ConvTranspose2d-53          [-1, 256, 64, 64]       2,097,408\n",
            "           Conv2d-54          [-1, 256, 64, 64]       1,179,648\n",
            "      BatchNorm2d-55          [-1, 256, 64, 64]             512\n",
            "             ReLU-56          [-1, 256, 64, 64]               0\n",
            "           Conv2d-57          [-1, 256, 64, 64]         589,824\n",
            "      BatchNorm2d-58          [-1, 256, 64, 64]             512\n",
            "             ReLU-59          [-1, 256, 64, 64]               0\n",
            "        ConvBlock-60          [-1, 256, 64, 64]               0\n",
            "          Decoder-61          [-1, 256, 64, 64]               0\n",
            "  ConvTranspose2d-62        [-1, 128, 128, 128]         524,416\n",
            "           Conv2d-63        [-1, 128, 128, 128]         294,912\n",
            "      BatchNorm2d-64        [-1, 128, 128, 128]             256\n",
            "             ReLU-65        [-1, 128, 128, 128]               0\n",
            "           Conv2d-66        [-1, 128, 128, 128]         147,456\n",
            "      BatchNorm2d-67        [-1, 128, 128, 128]             256\n",
            "             ReLU-68        [-1, 128, 128, 128]               0\n",
            "        ConvBlock-69        [-1, 128, 128, 128]               0\n",
            "          Decoder-70        [-1, 128, 128, 128]               0\n",
            "  ConvTranspose2d-71         [-1, 64, 256, 256]         131,136\n",
            "           Conv2d-72         [-1, 64, 256, 256]          73,728\n",
            "      BatchNorm2d-73         [-1, 64, 256, 256]             128\n",
            "             ReLU-74         [-1, 64, 256, 256]               0\n",
            "           Conv2d-75         [-1, 64, 256, 256]          36,864\n",
            "      BatchNorm2d-76         [-1, 64, 256, 256]             128\n",
            "             ReLU-77         [-1, 64, 256, 256]               0\n",
            "        ConvBlock-78         [-1, 64, 256, 256]               0\n",
            "          Decoder-79         [-1, 64, 256, 256]               0\n",
            "           Conv2d-80          [-1, 2, 256, 256]             130\n",
            "================================================================\n",
            "Total params: 39,392,386\n",
            "Trainable params: 39,392,386\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.25\n",
            "Forward/backward pass size (MB): 1020.00\n",
            "Params size (MB): 150.27\n",
            "Estimated Total Size (MB): 1170.52\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}